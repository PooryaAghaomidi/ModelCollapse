{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ljWE-qDpqEB4"
   },
   "source": [
    "# Preparation"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "seed_value= 42\n",
    "\n",
    "import random\n",
    "random.seed(seed_value)\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(seed_value)\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(seed_value)\n",
    "tf.keras.utils.set_random_seed(seed_value)"
   ],
   "metadata": {
    "id": "sUr3ZyJyqgvf",
    "ExecuteTime": {
     "end_time": "2024-11-23T05:31:06.392786600Z",
     "start_time": "2024-11-23T05:31:02.377804600Z"
    }
   },
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "print(tf.__version__)\n",
    "print(tf.config.list_physical_devices('GPU'))"
   ],
   "metadata": {
    "id": "lFlwHbbEqm_C",
    "outputId": "425f2df4-2ddd-4dfc-ad66-676b769608aa",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "ExecuteTime": {
     "end_time": "2024-11-23T05:31:09.670105200Z",
     "start_time": "2024-11-23T05:31:08.154879700Z"
    }
   },
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9.0\n",
      "[]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "UxBHr1ztqECA",
    "ExecuteTime": {
     "end_time": "2024-11-23T05:31:10.512413600Z",
     "start_time": "2024-11-23T05:31:10.498332100Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "pQGJI2aIqECB",
    "ExecuteTime": {
     "end_time": "2024-11-23T05:31:12.638128800Z",
     "start_time": "2024-11-23T05:31:12.624834500Z"
    }
   },
   "outputs": [],
   "source": [
    "num_epochs  = 100\n",
    "batch_size  = 16\n",
    "num_classes = 10\n",
    "shape       = (28, 28, 1)\n",
    "lr          = 0.0003\n",
    "opt         = keras.optimizers.Adamax(learning_rate=lr)\n",
    "los         = keras.losses.CategoricalCrossentropy()\n",
    "mtr         = [\"accuracy\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VkbDK0AAqECC"
   },
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "main_path = \"../Dataset/NoReg_Extra_5.npz\"\n",
    "\n",
    "sample = np.load(main_path)\n",
    "sample"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "IyJalcA1qECC",
    "outputId": "4e3fe176-81ee-48f4-9260-7456854ed5a7",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "ExecuteTime": {
     "end_time": "2024-11-23T05:27:42.968510700Z",
     "start_time": "2024-11-23T05:27:42.030606400Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training images: (54000, 28, 28, 1)\n",
      "Shape of validation images: (6000, 28, 28, 1)\n",
      "Shape of testing images: (10000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "def prepare_data(main_path, test_path, validation_split=0.1):\n",
    "    with np.load(test_path) as data:\n",
    "        x_test, y_test = data['x_test'], data['y_test']\n",
    "        \n",
    "    with np.load(main_path) as data:\n",
    "        \n",
    "        \n",
    "    # Normalize and reshape the data\n",
    "    x_train = x_train.astype(\"float32\") / 255.0\n",
    "    x_test = x_test.astype(\"float32\") / 255.0\n",
    "    \n",
    "    x_train = np.reshape(x_train, (-1, 28, 28, 1))\n",
    "    x_test = np.reshape(x_test, (-1, 28, 28, 1))\n",
    "    \n",
    "    y_train = keras.utils.to_categorical(y_train, 10)\n",
    "    y_test = keras.utils.to_categorical(y_test, 10)\n",
    "    \n",
    "    # Split the training data into train and validation sets\n",
    "    val_size = int(len(x_train) * validation_split)\n",
    "    x_val, y_val = x_train[:val_size], y_train[:val_size]\n",
    "    x_train, y_train = x_train[val_size:], y_train[val_size:]\n",
    "    \n",
    "    # Create TensorFlow datasets\n",
    "    train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "    val_dataset = tf.data.Dataset.from_tensor_slices((x_val, y_val))\n",
    "    test_dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
    "    \n",
    "    # Shuffle and batch the datasets\n",
    "    train_dataset = train_dataset.shuffle(buffer_size=1024).batch(batch_size)\n",
    "    val_dataset = val_dataset.shuffle(buffer_size=1024).batch(batch_size)\n",
    "    test_dataset = test_dataset.shuffle(buffer_size=1024).batch(batch_size)\n",
    "    \n",
    "    # Print the shapes\n",
    "    print(f\"Shape of training images: {x_train.shape}\")\n",
    "    print(f\"Shape of validation images: {x_val.shape}\")\n",
    "    print(f\"Shape of testing images: {x_test.shape}\")\n",
    "    \n",
    "    return train_dataset, val_dataset, test_dataset\n",
    "\n",
    "    \n",
    "train_dataset, val_dataset, test_dataset = prepare_data(main_path=\"../Dataset/mnist.npz\")    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xh4A2BtfqECF",
    "ExecuteTime": {
     "end_time": "2024-11-22T23:06:19.033004900Z",
     "start_time": "2024-11-22T23:06:18.970186300Z"
    }
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "-E8lf3QbqECF",
    "ExecuteTime": {
     "end_time": "2024-11-23T05:27:43.031673700Z",
     "start_time": "2024-11-23T05:27:42.969744500Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"discriminator\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 14, 14, 32)        320       \n",
      "                                                                 \n",
      " leaky_re_lu (LeakyReLU)     (None, 14, 14, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 7, 7, 64)          18496     \n",
      "                                                                 \n",
      " leaky_re_lu_1 (LeakyReLU)   (None, 7, 7, 64)          0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 4, 4, 128)         73856     \n",
      "                                                                 \n",
      " leaky_re_lu_2 (LeakyReLU)   (None, 4, 4, 128)         0         \n",
      "                                                                 \n",
      " global_max_pooling2d (Globa  (None, 128)              0         \n",
      " lMaxPooling2D)                                                  \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 101,578\n",
      "Trainable params: 101,578\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential([keras.layers.InputLayer(shape),\n",
    "                          layers.Conv2D(32, (3, 3), strides=(2, 2), padding=\"same\"),\n",
    "                          layers.LeakyReLU(alpha=0.2),\n",
    "                          layers.Conv2D(64, (3, 3), strides=(2, 2), padding=\"same\"),\n",
    "                          layers.LeakyReLU(alpha=0.2),\n",
    "                          layers.Conv2D(128, (3, 3), strides=(2, 2), padding=\"same\"),\n",
    "                          layers.LeakyReLU(alpha=0.2),\n",
    "                          layers.GlobalMaxPooling2D(),\n",
    "                          layers.Dense(64, activation=\"relu\"),\n",
    "                          layers.Dense(num_classes, activation=\"softmax\")],\n",
    "                         name=\"discriminator\")\n",
    "\n",
    "model.compile(optimizer=opt, loss=los, metrics=mtr)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-SJbTfPtqECG",
    "ExecuteTime": {
     "end_time": "2024-11-22T23:10:10.564855800Z",
     "start_time": "2024-11-22T23:06:19.064800900Z"
    }
   },
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pc-gS6NbqECG",
    "outputId": "b7a62951-22be-4a99-a7bf-bc741c464c7f",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2024-11-23T05:27:43.031673700Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "3372/3375 [============================>.] - ETA: 0s - loss: 0.5059 - accuracy: 0.8595"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Checkpoints\\Zero\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Checkpoints\\Zero\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3375/3375 [==============================] - 12s 3ms/step - loss: 0.5055 - accuracy: 0.8596 - val_loss: 0.2020 - val_accuracy: 0.9410 - lr: 3.0000e-04\n",
      "Epoch 2/100\n",
      "3353/3375 [============================>.] - ETA: 0s - loss: 0.1904 - accuracy: 0.9434"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Checkpoints\\Zero\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Checkpoints\\Zero\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3375/3375 [==============================] - 9s 3ms/step - loss: 0.1904 - accuracy: 0.9434 - val_loss: 0.1540 - val_accuracy: 0.9555 - lr: 3.0000e-04\n",
      "Epoch 3/100\n",
      "3359/3375 [============================>.] - ETA: 0s - loss: 0.1471 - accuracy: 0.9574"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Checkpoints\\Zero\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Checkpoints\\Zero\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3375/3375 [==============================] - 9s 3ms/step - loss: 0.1470 - accuracy: 0.9575 - val_loss: 0.1340 - val_accuracy: 0.9610 - lr: 3.0000e-04\n",
      "Epoch 4/100\n",
      "3357/3375 [============================>.] - ETA: 0s - loss: 0.1236 - accuracy: 0.9631"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Checkpoints\\Zero\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Checkpoints\\Zero\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3375/3375 [==============================] - 9s 3ms/step - loss: 0.1239 - accuracy: 0.9631 - val_loss: 0.1164 - val_accuracy: 0.9668 - lr: 3.0000e-04\n",
      "Epoch 5/100\n",
      "3357/3375 [============================>.] - ETA: 0s - loss: 0.1080 - accuracy: 0.9686"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Checkpoints\\Zero\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Checkpoints\\Zero\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3375/3375 [==============================] - 9s 3ms/step - loss: 0.1078 - accuracy: 0.9686 - val_loss: 0.1045 - val_accuracy: 0.9698 - lr: 3.0000e-04\n",
      "Epoch 6/100\n",
      "1210/3375 [=========>....................] - ETA: 5s - loss: 0.0996 - accuracy: 0.9706"
     ]
    }
   ],
   "source": [
    "def callback():\n",
    "  main_chk  = keras.callbacks.ModelCheckpoint(filepath=\"Checkpoints/Zero\", monitor='val_loss', mode='min', verbose=0, save_best_only=True)\n",
    "  early_st  = keras.callbacks.EarlyStopping(monitor='val_loss', mode='min', patience=30, verbose=0)\n",
    "  rduce_lr  = keras.callbacks.ReduceLROnPlateau(monitor='val_loss', mode='min', factor=0.5, patience=5, verbose=1, min_lr=0.00001)\n",
    "\n",
    "  return [main_chk, early_st, rduce_lr]\n",
    "\n",
    "model.fit(train_dataset, validation_data=val_dataset, epochs=num_epochs, batch_size=batch_size, callbacks=callback())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XHG9E07bqECH",
    "ExecuteTime": {
     "end_time": "2024-11-22T23:10:10.564855800Z",
     "start_time": "2024-11-22T23:10:10.564855800Z"
    }
   },
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_model = tf.keras.models.load_model(\"Checkpoints/Zero\")\n",
    "test_model.evaluate(test_dataset, verbose=1, batch_size=batch_size)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
