{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ljWE-qDpqEB4"
   },
   "source": [
    "# Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-23T14:33:29.301904200Z",
     "start_time": "2024-11-23T14:33:27.426446100Z"
    },
    "id": "sUr3ZyJyqgvf"
   },
   "outputs": [],
   "source": [
    "seed_value= 42\n",
    "\n",
    "import random\n",
    "random.seed(seed_value)\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(seed_value)\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(seed_value)\n",
    "tf.keras.utils.set_random_seed(seed_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-23T14:33:29.370352700Z",
     "start_time": "2024-11-23T14:33:29.300900100Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lFlwHbbEqm_C",
    "outputId": "425f2df4-2ddd-4dfc-ad66-676b769608aa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9.0\n",
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "print(tf.__version__)\n",
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-23T14:33:29.385018700Z",
     "start_time": "2024-11-23T14:33:29.362305900Z"
    },
    "id": "UxBHr1ztqECA"
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-23T14:33:29.420535800Z",
     "start_time": "2024-11-23T14:33:29.378978900Z"
    },
    "id": "pQGJI2aIqECB"
   },
   "outputs": [],
   "source": [
    "num_epochs  = 100\n",
    "batch_size  = 16\n",
    "num_classes = 10\n",
    "shape       = (28, 28, 1)\n",
    "lr          = 0.0003\n",
    "opt         = keras.optimizers.Adamax(learning_rate=lr)\n",
    "los         = keras.losses.CategoricalCrossentropy()\n",
    "mtr         = [\"accuracy\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VkbDK0AAqECC"
   },
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-23T14:33:31.010577Z",
     "start_time": "2024-11-23T14:33:29.394026500Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IyJalcA1qECC",
    "outputId": "4e3fe176-81ee-48f4-9260-7456854ed5a7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training images: (54000, 28, 28, 1)\n",
      "Shape of validation images: (6000, 28, 28, 1)\n",
      "Shape of testing images: (10000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "def prepare_data(main_path, test_path, validation_split=0.1):\n",
    "    with np.load(main_path) as data:\n",
    "        x_train, y_train = data['images'], data['labels']\n",
    "        \n",
    "    with np.load(test_path) as data:\n",
    "        x_test, y_test = data['x_test'], data['y_test']\n",
    "        \n",
    "    # Normalize and reshape the data\n",
    "    x_train = x_train.astype(\"float32\") / 255.0\n",
    "    x_test = x_test.astype(\"float32\") / 255.0\n",
    "    \n",
    "    x_train = np.reshape(x_train, (-1, 28, 28, 1))\n",
    "    x_test = np.reshape(x_test, (-1, 28, 28, 1))\n",
    "    \n",
    "    y_test = keras.utils.to_categorical(y_test, 10)\n",
    "    \n",
    "    # Split the training data into train and validation sets\n",
    "    val_size = int(len(x_train) * validation_split)\n",
    "    x_val, y_val = x_train[:val_size], y_train[:val_size]\n",
    "    x_train, y_train = x_train[val_size:], y_train[val_size:]\n",
    "    \n",
    "    # Create TensorFlow datasets\n",
    "    train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "    val_dataset = tf.data.Dataset.from_tensor_slices((x_val, y_val))\n",
    "    test_dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
    "    \n",
    "    # Shuffle and batch the datasets\n",
    "    train_dataset = train_dataset.shuffle(buffer_size=1024).batch(batch_size)\n",
    "    val_dataset = val_dataset.shuffle(buffer_size=1024).batch(batch_size)\n",
    "    test_dataset = test_dataset.shuffle(buffer_size=1024).batch(batch_size)\n",
    "    \n",
    "    # Print the shapes\n",
    "    print(f\"Shape of training images: {x_train.shape}\")\n",
    "    print(f\"Shape of validation images: {x_val.shape}\")\n",
    "    print(f\"Shape of testing images: {x_test.shape}\")\n",
    "    \n",
    "    return train_dataset, val_dataset, test_dataset\n",
    "\n",
    "    \n",
    "train_dataset, val_dataset, test_dataset = prepare_data(main_path=\"../Dataset/NoReg_Extra_6.npz\",\n",
    "                                                        test_path=\"../Dataset/mnist.npz\")    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-22T23:06:19.033004900Z",
     "start_time": "2024-11-22T23:06:18.970186300Z"
    },
    "id": "Xh4A2BtfqECF"
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-23T14:33:31.073878300Z",
     "start_time": "2024-11-23T14:33:31.022608900Z"
    },
    "id": "-E8lf3QbqECF"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"discriminator\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 14, 14, 32)        320       \n",
      "                                                                 \n",
      " leaky_re_lu (LeakyReLU)     (None, 14, 14, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 7, 7, 64)          18496     \n",
      "                                                                 \n",
      " leaky_re_lu_1 (LeakyReLU)   (None, 7, 7, 64)          0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 4, 4, 128)         73856     \n",
      "                                                                 \n",
      " leaky_re_lu_2 (LeakyReLU)   (None, 4, 4, 128)         0         \n",
      "                                                                 \n",
      " global_max_pooling2d (Globa  (None, 128)              0         \n",
      " lMaxPooling2D)                                                  \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 101,578\n",
      "Trainable params: 101,578\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential([keras.layers.InputLayer(shape),\n",
    "                          layers.Conv2D(32, (3, 3), strides=(2, 2), padding=\"same\"),\n",
    "                          layers.LeakyReLU(alpha=0.2),\n",
    "                          layers.Conv2D(64, (3, 3), strides=(2, 2), padding=\"same\"),\n",
    "                          layers.LeakyReLU(alpha=0.2),\n",
    "                          layers.Conv2D(128, (3, 3), strides=(2, 2), padding=\"same\"),\n",
    "                          layers.LeakyReLU(alpha=0.2),\n",
    "                          layers.GlobalMaxPooling2D(),\n",
    "                          layers.Dense(64, activation=\"relu\"),\n",
    "                          layers.Dense(num_classes, activation=\"softmax\")],\n",
    "                         name=\"discriminator\")\n",
    "\n",
    "model.compile(optimizer=opt, loss=los, metrics=mtr)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-22T23:10:10.564855800Z",
     "start_time": "2024-11-22T23:06:19.064800900Z"
    },
    "id": "-SJbTfPtqECG"
   },
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-23T14:42:53.150544400Z",
     "start_time": "2024-11-23T14:33:31.073878300Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "pc-gS6NbqECG",
    "outputId": "b7a62951-22be-4a99-a7bf-bc741c464c7f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "3375/3375 [==============================] - ETA: 0s - loss: 0.0752 - accuracy: 0.9934"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Checkpoints\\Extended\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Checkpoints\\Extended\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3375/3375 [==============================] - 26s 5ms/step - loss: 0.0752 - accuracy: 0.9934 - val_loss: 3.3913e-05 - val_accuracy: 1.0000 - lr: 3.0000e-04\n",
      "Epoch 2/100\n",
      "3365/3375 [============================>.] - ETA: 0s - loss: 8.1754e-06 - accuracy: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Checkpoints\\Extended\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Checkpoints\\Extended\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3375/3375 [==============================] - 19s 6ms/step - loss: 8.1531e-06 - accuracy: 1.0000 - val_loss: 6.4476e-07 - val_accuracy: 1.0000 - lr: 3.0000e-04\n",
      "Epoch 3/100\n",
      "3367/3375 [============================>.] - ETA: 0s - loss: 1.4340e-07 - accuracy: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Checkpoints\\Extended\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Checkpoints\\Extended\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3375/3375 [==============================] - 19s 6ms/step - loss: 1.4307e-07 - accuracy: 1.0000 - val_loss: 3.5167e-09 - val_accuracy: 1.0000 - lr: 3.0000e-04\n",
      "Epoch 4/100\n",
      "3369/3375 [============================>.] - ETA: 0s - loss: 3.5279e-08 - accuracy: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Checkpoints\\Extended\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Checkpoints\\Extended\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3375/3375 [==============================] - 17s 5ms/step - loss: 3.5218e-08 - accuracy: 1.0000 - val_loss: 1.5895e-10 - val_accuracy: 1.0000 - lr: 3.0000e-04\n",
      "Epoch 5/100\n",
      "3370/3375 [============================>.] - ETA: 0s - loss: 1.7908e-10 - accuracy: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Checkpoints\\Extended\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Checkpoints\\Extended\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3375/3375 [==============================] - 18s 5ms/step - loss: 1.7881e-10 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - lr: 3.0000e-04\n",
      "Epoch 6/100\n",
      "3372/3375 [============================>.] - ETA: 0s - loss: 8.8503e-05 - accuracy: 1.0000\n",
      "Epoch 6: ReduceLROnPlateau reducing learning rate to 0.0001500000071246177.\n",
      "3375/3375 [==============================] - 16s 5ms/step - loss: 8.8424e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - lr: 3.0000e-04\n",
      "Epoch 7/100\n",
      "3375/3375 [==============================] - 16s 5ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - lr: 1.5000e-04\n",
      "Epoch 8/100\n",
      "3375/3375 [==============================] - 16s 5ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - lr: 1.5000e-04\n",
      "Epoch 9/100\n",
      "3375/3375 [==============================] - 16s 5ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - lr: 1.5000e-04\n",
      "Epoch 10/100\n",
      "3375/3375 [==============================] - 16s 5ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - lr: 1.5000e-04\n",
      "Epoch 11/100\n",
      "3368/3375 [============================>.] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 7.500000356230885e-05.\n",
      "3375/3375 [==============================] - 16s 5ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - lr: 1.5000e-04\n",
      "Epoch 12/100\n",
      "3375/3375 [==============================] - 16s 5ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - lr: 7.5000e-05\n",
      "Epoch 13/100\n",
      "3375/3375 [==============================] - 16s 5ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - lr: 7.5000e-05\n",
      "Epoch 14/100\n",
      "3375/3375 [==============================] - 16s 5ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - lr: 7.5000e-05\n",
      "Epoch 15/100\n",
      "3375/3375 [==============================] - 16s 5ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - lr: 7.5000e-05\n",
      "Epoch 16/100\n",
      "3364/3375 [============================>.] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 3.7500001781154424e-05.\n",
      "3375/3375 [==============================] - 16s 5ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - lr: 7.5000e-05\n",
      "Epoch 17/100\n",
      "3375/3375 [==============================] - 16s 5ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - lr: 3.7500e-05\n",
      "Epoch 18/100\n",
      "3375/3375 [==============================] - 16s 5ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - lr: 3.7500e-05\n",
      "Epoch 19/100\n",
      "3375/3375 [==============================] - 16s 5ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - lr: 3.7500e-05\n",
      "Epoch 20/100\n",
      "3375/3375 [==============================] - 16s 5ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - lr: 3.7500e-05\n",
      "Epoch 21/100\n",
      "3372/3375 [============================>.] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 1.8750000890577212e-05.\n",
      "3375/3375 [==============================] - 16s 5ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - lr: 3.7500e-05\n",
      "Epoch 22/100\n",
      "3375/3375 [==============================] - 17s 5ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - lr: 1.8750e-05\n",
      "Epoch 23/100\n",
      "3375/3375 [==============================] - 17s 5ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - lr: 1.8750e-05\n",
      "Epoch 24/100\n",
      "3375/3375 [==============================] - 17s 5ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - lr: 1.8750e-05\n",
      "Epoch 25/100\n",
      "3375/3375 [==============================] - 16s 5ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - lr: 1.8750e-05\n",
      "Epoch 26/100\n",
      "3370/3375 [============================>.] - ETA: 0s - loss: 0.0000e+00 - accuracy: 1.0000\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "3375/3375 [==============================] - 16s 5ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - lr: 1.8750e-05\n",
      "Epoch 27/100\n",
      "3375/3375 [==============================] - 16s 5ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 28/100\n",
      "3375/3375 [==============================] - 16s 5ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 29/100\n",
      "3375/3375 [==============================] - 16s 5ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 30/100\n",
      "3375/3375 [==============================] - 16s 5ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 31/100\n",
      "3375/3375 [==============================] - 16s 5ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 32/100\n",
      "3375/3375 [==============================] - 16s 5ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 33/100\n",
      "3375/3375 [==============================] - 16s 5ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 34/100\n",
      "3375/3375 [==============================] - 16s 5ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - lr: 1.0000e-05\n",
      "Epoch 35/100\n",
      "3375/3375 [==============================] - 16s 5ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000 - lr: 1.0000e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2e60ff97520>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def callback():\n",
    "  main_chk  = keras.callbacks.ModelCheckpoint(filepath=\"Checkpoints/Extended\", monitor='val_loss', mode='min', verbose=0, save_best_only=True)\n",
    "  early_st  = keras.callbacks.EarlyStopping(monitor='val_loss', mode='min', patience=30, verbose=0)\n",
    "  rduce_lr  = keras.callbacks.ReduceLROnPlateau(monitor='val_loss', mode='min', factor=0.5, patience=5, verbose=1, min_lr=0.00001)\n",
    "\n",
    "  return [main_chk, early_st, rduce_lr]\n",
    "\n",
    "model.fit(train_dataset, validation_data=val_dataset, epochs=num_epochs, batch_size=batch_size, callbacks=callback())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-22T23:10:10.564855800Z",
     "start_time": "2024-11-22T23:10:10.564855800Z"
    },
    "id": "XHG9E07bqECH"
   },
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-23T14:42:54.382426800Z",
     "start_time": "2024-11-23T14:42:53.150544400Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 3s 4ms/step - loss: 30.8310 - accuracy: 0.2289\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[30.83095932006836, 0.2289000004529953]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_model = tf.keras.models.load_model(\"Checkpoints/Extended\")\n",
    "test_model.evaluate(test_dataset, verbose=1, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
